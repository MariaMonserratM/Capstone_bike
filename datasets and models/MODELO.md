# 游 CAPSTONE PROJECT: DOCK AVAILABILITY PREDICTION

## 1. Introducci칩n
Bicing es el servicio p칰blico de alquiler de bicis de la ciudad de Barcelona. Cuenta a d칤a de hoy con m치s de 500 estaciones repartidas por toda la ciudad. El sistema cuenta con una aplicaci칩n donde explorar en tiempo real la disponibilidad de bicis y de espacios para dejar la bici en las diferentes estaciones. Sin embargo, no cuenta con un predictor que determine el porcentaje de bicis o sitios probables que habr치 en un determinado momento del tiempo para una estaci칩n determinada.

### 1.1 Objetivo y evaluaci칩n
El presente proyecto tiene como objetivo la generaci칩n de un modelo de predicci칩n del porcentaje de sitios libres (docks) en una estaci칩n de Bicing determinada y en un momento determinado del tiempo.
La valoraci칩n de la exactitud del modelo se ha medido mediante RMSE (Root Mean Squared Error) que cuantifica la diferencia entre los valores predichos y los valores reales, indicando el nivel de dispersi칩n de los datos.
El env칤o del resultado del modelo y la evaluaci칩n se ha realizado a trav칠s de una competici칩n con otros equipos en la plataforma Kaggle: https://www.kaggle.com/competitions/2024-online-bike-availability-prediction


## 2. Metodolog칤a y resultados
### Primera parte: dataset y modelo simple de regresi칩n lineal
#### Or칤gen de los datos
El Ayuntamiento de Barcelona, a trav칠s de su portal de datos abiertos, opendata-ajuntament.barcelona.cat, pone a disposici칩n de la ciudadan칤a datos sobre el estado de las estaciones de Bicing. En concreto, los datos sobre la disponibilidad de bicis y de huecos libres se puede descargar para los diferentes meses del a침o en la siguiente p치gina: https://opendata-ajuntament.barcelona.cat/data/ca/dataset/estat-estacions-bicing.

Para este proyecto se han usado como datos de entrenamiento los comprendidos entre los a침os 2020 y 2023, y como datos de test los comprendidos entre enero y abril de 2024.

Solo se han usado las estaciones que se encuentran en el dataset de test (399 estaciones diferentes) que se puede bajar del propio kaggle (documento: _metadata_sample_submission_2024_)

#### Primer dataset
El Ayuntamiento de Barcelona recoge el estado de las diferentes estaciones cada 5 minutos aproximadamente. Para disminuir la complejidad de los datos y del modelo, se ha calculado la media de la disponibilidad de huecos por hora para cada estaci칩n, y se ha construido un dataset inicial con los datos de la estaci칩n, el a침o, el mes, el d칤a, la hora, y la disponibilidad de huecos en las 4 horas anteriores a la hora diana. A estas 칰ltimas variables las hemos denominado _variables contexto_.

El c칩digo para la generaci칩n del dataset inicial con todos los datos para los a침os 2020 a 2023 se puede explorar en el archivo _Load_concatenate_data_code.py_ del directorio _datasets and models_.
El c칩digo para la generaci칩n del dataset de entrenamiento inicial anteriormente descrito se puede explorar en el archivo _Bike_preprocesed_code.py_ del directorio _datasets and models_.

#### Primer modelo simple
Para realizar la primera submisi칩n al Kaggle, se ha hecho un split temporal del dataset de entrenamiento, de manera que se ha usado el 80% de los datos como entrenamiento y el 20% como datos de validaci칩n. A continauci칩n se ha entrenado un modelo de regresi칩n lineal obteni칠ndose un RMSE de 0.110990656 y un R2 de 0.820732338.
Para hacer la predicci칩n con los datos de test, se ha entrenado el modelo de nuevo con el dataset completo de training.

### Segunda parte: Enriquecimiento del dataset y resultado de otros modelos
#### Variables extras a침adidas al dataset
El c칩digo con las funciones y la extracci칩n de la 칰ltima versi칩n del dataset de training y test se puede explorar en el documento _Extra_variables_dataset.py_ del directorio _datasets and models_

Para enriquecer el dataset con variables que pudieran tener un valor predictor nos hemos centrado en caracter칤sticas geogr치ficas de la estacion y en caracter칤sicas temporales.

El listado y la localizaci칩n de elementos de inter칠s de la ciudad como museos, cines, teatros, bares, etc. han sido obtenido del portal de datos abiertos del Ayuntamiento de Barcelona anteriormente citado.

La localizaci칩n de las diferentes facultades de las universidades de la ciudad y La correspondencia entre los c칩digos postales y los barrios mayoritarios a los que pertenecen se han obtenido con la ayuda de ChatGPT basada en la arquitectura GPT-4 de OpenAI.

Como caracter칤sticas de la estaci칩n que pudieran tener un valor predictivo se han a침adido las siguientes variables:
* **Capacidad de la estaci칩n**: el tama침o total de la estaci칩n puede influir en el porcentaje de disponibilidad.
* **Altitud**: el uso de la bici probablemente tenga una direccionalidad de zonas altas hacia zonas bajas. Estaciones que se encuentran en zonas m치s altas tendran m치s disponibilidad de huuecos que zonas las que se encuentran en zonas bajas.
* **Latitud y Longitud**: la localizaci칩n exacta de la estaci칩n podr칤a estar relacionada con los patrones de uso. Necesitamos esta localizaci칩n para calcular distancias a otros elementos de inter칠s.
* **C칩digo postal y barrio**: la zona en la que se localiza una estaci칩n puede marcar el patr칩n de uso de la misma.
* **N칰mero de otras estaciones de bicing cercanas**: la cercan칤a de otras estaciones puede generar tambi칠n patrones de uso en una estaci칩n.
* **Cercan칤a a estaciones de transporte p칰blico**: el uso complementario de la bici y el transporte p칰blico puede determinar patrones de uso.
* **Cercan칤a a alguna facultad**: las estaciones cercanas a las facultades se suelen llenar por la ma침ana y vaciar por la tarde
* **N칰mero de facultades cercanas**: cuanto m치s grande es el campus, m치s gente puede podr칤a hacer uso del bicing para llegar a la universidad o para volver a casa.
* **Cercan칤a a bibliotecas**: elementos de inter칠s
* **Cercan칤a a museos**: elementos de inter칠s con posible relaci칩n con d칤as de fiesta o fin de semana
* **Cercan칤a a cines y teatros**: elementos de inter칠s con posible relaci칩n con d칤as de fiesta o fin de semana
* **Cercan칤a a bares y clubes**: elementos de inter칠s con posible relaci칩n con d칤as de fiesta o fin de semana
* **N칰mero de bares cercanos**: una zona con gran cantidad de bares o clubes puede ser una zona de salir con mayor probabilidad de generar un patr칩n de uso en las estaciones adyacentes

Como caracter칤sticas relacionadas con la temporalidad se han a침adido las siguientes variables:
* **Momento del d칤a**: los patrones de uso podr칤an cambiar entre la noche, las primeras horas de la ma침ana, las primeras horas de la tarde, etc.
* **Estaci칩n**: los patrones de uso podr칤an variar seg칰n sea invierno, primavera, verano u oto침o.
* **Si es fin de semana o fiesta**: los patrones de uso podr칤an variar dependiendo de si es un d칤a de trabajo o no.

Por 칰ltimo, al hacer el an치lisis de predictores en los diferentes modelos, se ha visto que la variable que mejor predice el target es la disponibilidad de huecos en la hora anterior (ctx-1), as칤 que se ha a침adido la **media de la disponibilidad de huecos en las estaciones adyacentes en la hora anterior** para explorar tambi칠n su capacidad predictiva.

Se ha valorado la inclusi칩n de otras variables que finalmente no han sido inclu칤das en el dataset para su testeado:
Climatolog칤a: se desech칩 la idea de incluir variables relativas a la climatolog칤a por dos razones, 1) los datos abiertos de la AEMET solo proporcionan datos medios diarios y no por hora. Asignar el dato medio del d칤a a todas las horas, podr칤a penalizar el poder predictivo del modelo; y b) la ciudad de Barcelona se caracteriza por tener un clima no muy extremo durante todo el a침o y las precipitaciones son excasas, lo que una hipot칠tica variable precipitaci칩n si/no, ser칤a demasiado desbalanceada y no beneficiar칤a al modelo.
Distancia a la playa y a la monta침a: como estas caracter칤sticas est치n muy correlacionadas con la altitud, se decidi칩 no inclirlas para su testeado.


## 3. Exploraci칩n de los Datos, Selecci칩n de Variables y Modelizaci칩n

### Exploraci칩n de los datos

#### A침o 2020 y COVID-19
El a침o 2020 se caracteriz칩 por ser muy at칤pico debido a la pandemia mundial de COVID-19 que alter칩 dr치sticamente los patrones habituales de actividad humana, incluyendo el uso del transporte. Incorporar datos de este a침o en nuestros modelos de aprendizaje autom치tico podr칤a conducir a interpretaciones inexactas y a la identificaci칩n de patrones que no reflejan las condiciones normales.

* **Comportamiento No Representativo de los Usuarios**: Confinamientos y Restricciones.

* **Patrones de Datos An칩malos**: Eventos espec칤ficos relacionados con la pandemia, como fases de reapertura o nuevos confinamientos, crearon cambios bruscos y no recurrentes en los patrones de uso.

* **Impacto en la Precisi칩n del Modelo**: Incluir datos de 2020 podr칤a introducir anomal칤as y ruido, llevando al modelo a aprender patrones que no se generalizan bien a otros a침os.

![covid](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/52b8c6ec-e1d2-4b8a-8bc5-9b57459f4b63)

En 2020, observamos una clara diferencia en el porcentaje de disponibilidad de docks en comparaci칩n con los a침os 2021, 2022 y 2023, que muestran patrones similares entre ellos. El porcentaje promedio de docks disponibles por mes es relativamente constante a lo largo de estos a침os, excepto en 2020 (especialmente en marzo, abril, mayo y junio).

Hemos decidido excluir 2020, nos aseguramos de que los datos de entrenamiento reflejen patrones regulares y predecibles de uso de bicicletas, lo que mejora la robustez y la fiabilidad de nuestras predicciones. Los modelos entrenados con datos de a침os m치s representativos (por ejemplo, 2021, 2022, 2023) tienen m치s probabilidades de generalizarse bien a las condiciones futuras, proporcionando insights m치s precisos y 칰tiles. Por estas razones, hemos decidido excluir los datos de 2020 en nuestros modelos predictivos.

#### Estaciones del a침o

Durante el invierno y la primavera, el porcentaje medio de docks disponibles por hora es menor que en verano y oto침o. Esto se puede explicar por el hecho de que durante los meses m치s c치lidos, la gente tiende a usar m치s el Bicing y por eso se puede encontrar un mayor porcentaje de docks disponibles.

![season](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/d3f46d8d-e737-499a-9565-73636a466de8)

#### D칤as de la semana

Hay una diferencia entre el porcentaje medio de docks disponibles seg칰n si es d칤a laborable o fin de semana.

![day_of_week](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/730e878b-066c-4cd5-b47e-9a278e051e8d)

#### Momento del d칤a

Observamos c칩mo durante la ma침ana y la tarde es cuando generalmente hay menos docks disponibles. Y durante la noche y la madrugada es cuando hay m치s docks disponibles. Tiene sentido porque durante la noche menos personas usan las bicicletas y, por lo tanto, las estaciones est치n m치s llenas.

![time_of_day](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/9e63057c-2c81-4ca7-b9b5-0d14cc9503bb)

#### Altitud

La disponibilidad de docks en las diferentes estaciones de Barcelona est치 significativamente influenciada por la altitud en la que se encuentran.

* **Preferencia por las pendientes**: Las estaciones situadas a mayor altitud generalmente tienen m치s docks disponibles. Esto se debe a que los usuarios prefieren montar en bicicleta cuesta abajo, lo que requiere menos esfuerzo f칤sico. En consecuencia, las bicicletas se coger con frecuencia de estaciones en altitudes m치s altas y se conducen a 치reas de menor altitud.

* **Acumulaci칩n en altitudes bajas**: La tendencia de ir cuesta abajo provoca una acumulaci칩n de bicicletas en las estaciones de menor altitud, donde los usuarios terminan sus viajes. Como resultado, estas estaciones a menudo tienen menos docks disponibles.

Para abordar estos desequilibrios, los operadores del Bicing a menudo necesitan realizar tareas de reequilibrio, donde las bicicletas se transportan de estaciones de menor a mayor altitud. Sin embargo, estas tareas solo pueden mitigar parcialmente los patrones de flujo natural dictados por la altitud.

![altitude](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/7d49174b-0068-4c45-af1a-f33c80b61f54)

#### Nearby Stations y Nearby Colleges ( y otras variables "near")

Algunas variables muestran diferencias aparentemente significativas cuando hacemos boxplots, como son la variable nearby_stations y nearby_colleges. Sin embargo, ser치 tras la evaluaci칩n de los modelos y la importancia de sus caracter칤sticas finales que se decidir치 qu칠 variables a침adir al modelo predictivo.

<img width="580" alt="nearby_stations" src="https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/07874c6e-01fd-457e-ae27-d14116d2908a">

<img width="578" alt="nearby_colleges" src="https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/f7ff2615-37cf-4316-bdee-e12deeb2d401">

#### Fin de semana y festivos

Hemos decidido unir en una sola variable las variables is_weekend y is_holiday. Al final, solo nos interesa saber si estamos tratando con d칤as de tipolog칤a festivo (fines de semana y d칤as festivos adicionales) ya que el comportamiento es muy similar. As칤 que hemos creado la variable is_not_workday para reflejarlo.

<img width="592" alt="is_not_workday" src="https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/68ebf6e1-3bc3-42d6-a5a9-ea624bfc4a73">

#### Barrio y postcode

Si est치s familiarizado con Barcelona, puedes ver claramente c칩mo la altitud de cada barrio afecta la disponibilidad de docks. Por lo tanto, la variable de altitud est치, en cierta medida, impl칤cita en la variable de barrio. Sin embargo, otras caracter칤sticas del barrio tambi칠n pueden ser importantes para la disponibilidad de docks, lo que indica que esta variable puede a침adir informaci칩n adicional a nuestro conjunto de datos.

![neighborhood](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/29306882-f466-43fb-909d-20ffea1bcb11)


El c칩digo postal y el barrio est치n altamente correlacionados. Sin embargo, algunos c칩digos postales pueden pertenecer a m치s de un barrio. Al final, solo utilizaremos una de estas dos variables en nuestro modelo, si es el caso.

![post_code](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/e190a10b-9475-45da-9717-87dba2290267)

#### Correlaciones entre variables num칠ricas

![heat_map](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/4313158f-3081-41da-986c-ff2340b5e3e5)

Las variables num칠ricas m치s correlacionadas con la variable target son: ctx-1, ctx-2, ctx-3, ctx-4, altitude y nearby_stations. Adem치s, las variables contexto est치n correlacionadas entre ellas, lo cual tiene sentido. Variables como la hora y el mes, si las analizamos como variables num칠ricas no parecen tener correlaci칩n. Sin embargo, si tratamos la variable hora como categ칩rica (o usamos la variable hour_info) si que posiblemente pueda aportar un valor a침adido a nuestros modelos.

### Entrenamiento y evaluaci칩n de los modelos predictivos

Para dividir nuestro dataframe (df) en conjuntos de datos de entrenamiento y validaci칩n debemos tener en cuenta que estamos manejando datos temporales, por lo que durante el proceso de divisi칩n, debemos respetar el orden temporal. Por ejemplo, no podemos tener datos de diciembre de 2023 en nuestro conjunto de datos de entrenamiento y datos de 2021 en nuestro conjunto de datos de validaci칩n. Adem치s, es importante tener en cuenta la variable station_id durante este paso.

Se han explorado distintos tipos de modelos predictivos, empezando por el m치s simple:

#### Linear Regression

Para escoger las variables que queremos usar en nuestro modelo de regresion lineal nos hemos basado en el estudio previo de correlaci칩n de variables con nuestra variable target y tambi칠n en las limitaciones y ventajas que presenta un modelo como este.

Las variables escogidas han sido: ['ctx-1', 'ctx-2', 'ctx-3', 'ctx-4', 'hour', 'altitude', 'is_weekend']

Por un lado, hemos escogido las variables que m치s correlaci칩n lineal tienen con la variable target as칤 como aquellas, aunque sean categoricas (binarias) pueden ser facilmente interpretables por un modelo simple de regresion lineal. No hemos querido a침adir variables categoricas con un gran n칰mero de opciones dentro de ellas ya que este tipo de modelos no son los m치s adecuados para tratar con variables de esas caracteristicas ni tampoco hemos querido a침adir much칤simas variables ya que para ello disponemos de modelos m치s potentes y complejos capaces de encontrar relaciones no lineales entre variables.

Los resultados han sido:
* **Root Mean Squared Error**: 0.10308152279128933
* **Validation R^2 Score**: 0.8484644676948296

La variable que m치s peso tiene en el modelo es ctx-1, seguida de la ctx-2. La variable altitude est치 en quinta posici칩n de importancia y is_weekend la 칰ltima.

**Regresi칩n Lineal**:
* Simplicidad: F치cil de implementar e interpretar. Sirve como un buen modelo de referencia.
* Relaciones Lineales: Asume una relaci칩n lineal entre las caracter칤sticas y la variable objetivo, lo cual puede no captar las complejidades en los datos.
* Independencia de Caracter칤sticas: Asume la independencia de las caracter칤sticas, lo cual puede no ser cierto en escenarios del mundo real.
* Manejo Limitado de Variables Categ칩ricas: Requiere un procesamiento extensivo de variables categ칩ricas. Tambi칠n puede manejar caracter칤sticas binarias, pero las trata de manera lineal, lo cual puede no capturar todas las complejidades.

#### XGBoost

XGBoost generalmente tiene una mayor capacidad para manejar datos categ칩ricos codificados (onehot encoder) y caracter칤sticas binarias debido a su habilidad para capturar relaciones no lineales, manejar eficientemente datos dispersos y modelar autom치ticamente interacciones entre caracter칤sticas. Mientras que la regresi칩n lineal puede trabajar con estos tipos de datos, frecuentemente no logra capturar las complejidades y las interacciones que XGBoost puede modelar de manera efectiva, lo que puede llevar a un mejor rendimiento predictivo potencialmente con XGBoost.

Aprovechando los benficios de un modelo como XGBoost, en este caso hemos decidido a침adir m치s variables a nuestro modelo, para probar si 칠stas realmente aportan alg칰n beneficio a la predicci칩n.

Las variables escogidas han sido:
['ctx-1', 'ctx-2', 'ctx-3', 'ctx-4', 'hour', 'altitude', 'is_weekend', 'hour_info', 'season_info', 'post_code', 'nearby_stations', 'near_transport', 'near_college', 'nearby_colleges', 'near_museum']

Los resultados de la predicci칩n:
* **Root Mean Squared Error**: 0.09632863965409555
* **Validation R^2 Score**: 0.8676683638545032

Vemos que el resultado ha mejorado respecto al modelo anterior. Sin embargo, tambi칠n hemos a침adido complejidad al modelo con la suma de nuevas variables.

**Feature Importance**:

En este caso volvemos a observar como las variables m치s importances son ctx-1 (con mucha diferencia), ctx-2, hour_info_early_morning, post_code_8002, ...otras variables que nacen de post_code..., altitude (en 10a posici칩n de importancia), etc.
Vemos como la variable altitud pierde peso en nuestor modelo: probablemente se deba a que hemos a침adido la variable post_code que de alguna manera tiene impl칤cita tambi칠n la altitud.

#### Neural Networks

A continuaci칩n hemos querido probar un modelo de red neuronal para ver si aporta alguna mejora dadas sus caracter칤sticas:

* **Relaciones no lineales**: Las redes neuronales pueden capturar relaciones complejas y no lineales entre las caracter칤sticas y la variable objetivo. Variables que parecen menos importantes en modelos lineales o basados en 치rboles (como XGBoost) pueden contribuir de manera m치s significativa en las redes neuronales si influyen en el resultado a trav칠s de interacciones no lineales.

* **Feature Engineering**: Las redes neuronales aprenden autom치ticamente las interacciones y representaciones de las caracter칤sticas a partir de los datos, mientras que en XGBoost y Regresi칩n Lineal, el proceso de feature engineering (crear nuevas caracter칤sticas o transformaciones) puede ser m치s cr칤tica.

Hemos utilizado las mismas variables que en el modelo anterior (XGBoost) y hemos codificado las variables categ칩ricas usando OneHotEncoder y hemos escalado los datos num칠ricos usando MinMaxScaler [0, 1], tal y como hemos hecho tambi칠n con XGBoost.

Evaluaci칩n del modelo:
* **Mean Squared Error**: 0.009247507075219633
* **Root Mean Squared Error**: 0.09616395933622758
* **Validation R^2 Score**: 0.8681204368450266

Ha mejorado el modelo respecto el XGBoost anterior, sin embargo tambi칠n ha aumentado la complejidad del modelo y el tiempo de computaci칩n.

Feature Importance:

![feature_imp_nn](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/3f1260d3-4cae-45ef-bbfd-3471f83dfa32)

Resulta curioso observar como variables que en los otros modelos no aparec칤an como impportances, en este modelo de NN s칤 que aparecen: nearby_stations es un ejemplo, esto puede deberse a que las redes neuronales pueden captar relaciones m치s sutiles que otros modelos (relaciones no lineales en contextos distintos).

#### Light GBM

Hemos decidido probar este tipo de modelo, similar al XGBoost pero con algunas peculiaridades:

* **Soporte para Caracter칤sticas Categ칩ricas**: LightGBM cuenta con soporte incorporado para caracter칤sticas categ칩ricas, las cuales pueden ser utilizadas sin necesidad de hacer OneHotEncoder. Esto puede ahorrar tiempo de preprocesamiento y memoria, especialmente al tratar con conjuntos de datos que contienen variables categ칩ricas con alta cardinalidad, como es el caso de post_code.
* **Ajuste de Par치metros**: LightGBM ofrece par치metros adicionales para ajustar finamente el rendimiento del modelo, como manejar el sobreajuste mediante regularizaci칩n y controlar el crecimiento del 치rbol con par치metros como num_leaves y min_data_in_leaf. Esta flexibilidad nos permite optimizar el rendimiento del modelo de manera m치s efectiva.

Las variables que hemos seleccionado para probar este modelo han sido:
['ctx-1', 'ctx-2', 'post_code', 'hour', 'altitude', 'is_not_workday']

En este caso, vamos a tratar la variable "hour" y "post_code" como categ칩ricas.

<img width="336" alt="vairables_lgbm" src="https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/ac9ab516-5fa8-4038-845e-e3f9b2410aa4">

Resultado del modelo:

* **Mean Squared Error**: 0.009171869657551976

* **R^2 Score**: 0.8691991091314109

Observamos como el modelo vuelve a mejorar respecto al anterior, aunque ligeramente. Este modelo es m치s sencillo a nivel de selecci칩n de variables y con un coste computacional inferior.

**Feature Importance**

<img width="282" alt="feature_imp_values_lgbm" src="https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/f698a473-eeb6-4bb1-9885-1186d106461c">

![feature_imp_lgbm](https://github.com/MariaMonserratM/Capstone_bike/assets/66376420/f412fbc8-cd48-47e6-b9aa-f7b279bc59e6)

De nuevo, la variable m치s importante para la predicci칩n es ctx-1. En este caso, la tercera variable m치s importante es post_code.

#### Conclusiones y selecci칩n de modelo final

Todos los modelos destacan ctx-1 y ctx-2 como variables cruciales, lo cual es l칩gico dado su relevancia contextual. Otras variables a침adidas a nuestro modelo proporcionan mejoras modestas en el rendimiento. Su importancia no es tan alta como en ctx-1, pero ayudan a explicar las predicciones en casos espec칤ficos: donde la altitud es relevante, tambi칠n el c칩digo postal, etc.

A lo largo de este proyecto, otras variables evaluadas no beneficiaron sustancialmente nuestro modelo. Por lo tanto, optamos por la simplicidad al incluir solo las variables m치s relevantes para la predicci칩n, como lo hicimos con el modelo Light GBM.

Es destacable que la variable nearby_stations muestra una importancia significativa en el modelo de Neural Network, lo cual no se observa en los otros modelos.

Adem치s, destacar que la influencia de la altitud se ve mitigada en cierta medida por los esfuerzos de los operadores de las estaciones de Bicing para reequilibrar las bicicletas. Aunque nuestros datos capturan este efecto, su impacto es menos pronunciado.

Las variables bajo consideraci칩n podr칤an ser mejoradas potencialmente recalculando las distancias de manera diferente (nearby_stations, nearby_colleges, etc.). Adem치s, la creaci칩n de una nueva variable que indicase el tipo de estaci칩n basada en la ubicaci칩n, altitud, c칩digo postal, etc., y clusterizar las estaciones seg칰n sus patrones de uso (por ejemplo, estaciones con frecuentes excesos o d칠ficits de bicicletas) podr칤a mejorar a칰n m치s el rendimiento de nuestro modelo.

En conclusi칩n, hemos optado por el modelo Light GBM con un conjunto m칤nimo de caracter칤sticas para predecir el porcentaje de docks disponibles. Si bien el modelo de Red Neuronal muestra un rendimiento comparable, introduce complejidad adicional. Es importante se침alar que, a pesar de su rendimiento ligeramente inferior, la simplicidad del modelo de regresi칩n lineal ofrece un buen resultado.

#### Limitaciones del modelo y mejoras
Como se ha demostrado, las variables adicionales a침adidas al dataset no tienen un peso relativo muy alto comparadas con la variable predictiva principal que es la ctx-1.

El momento del d칤a, si es un d칤a de trabajo o no, y la altitud son otras de las variables que usa el modelo, aunque tengan un peso menor.

Para mejorar el valor predictivo de las variables relacionadas con los elementos de inter칠s de la ciudad podr칤amos reducir el n칰mero de elementos y dej치r 칰nicamente los m치s importantes. Tambi칠n podr칤amos variar la distancia. Es posible que las distancias elegidas (entre 200-300 seg칰n el elemento) sea demasiado grande para generar diferencias entre estaciones.
Creemos que la media de la disponibilidad de estaciones adyacentes en la hora anterior puede tener un valor predictivo mayor si se usaran todas las estaciones del servicio, y no 칰nicamente las 399 que hay en el dataset de test. Adem치s, esta medida es poco representativa, ya que por la naturaleza del dataset, cuyo target es 칰nicamente 1 de cada 5 horas, hace complicado encontrar el dato para las estaciones adyacentes para la hora exacta de la estaci칩n sobre la que estamos haciendo el c치lculo.

