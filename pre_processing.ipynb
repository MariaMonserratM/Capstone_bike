{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install dask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Define the path to the directory containing the CSV files\n",
        "csv_files = glob.glob('bicing_data/*.csv')\n",
        "\n",
        "# Read all files into a single Dask DataFrame, treating all columns as strings initially\n",
        "df = dd.read_csv(csv_files, assume_missing=True, dtype=str)\n",
        "\n",
        "# Get all unique columns across all CSV files\n",
        "all_columns = set(df.columns)\n",
        "\n",
        "# Ensure all columns are present in the DataFrame\n",
        "for col in all_columns:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "\n",
        "def parse_dates(df):\n",
        "    for col in ['last_updated', 'last_reported']:\n",
        "        df[col] = dd.to_datetime(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "\n",
        "def clean_is_installed(value):\n",
        "    if isinstance(value, str):\n",
        "        value = value.lower()\n",
        "        if value in ['true', 'false']:\n",
        "            return 1 if value == 'true' else 0\n",
        "    try:\n",
        "        return float(value)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "def to_bool(x):\n",
        "    if pd.isna(x):\n",
        "        return False\n",
        "    if isinstance(x, str):\n",
        "        return x.lower() in ['true', '1']\n",
        "    return bool(x)\n",
        "\n",
        "def clean_is_renting_returning(value):\n",
        "    if value in ['0', '1']:\n",
        "        return int(value)\n",
        "    return None\n",
        "\n",
        "\n",
        "def clean_num_docks_available(value):\n",
        "    try:\n",
        "        return float(value)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "\n",
        "# Apply the cleaning functions to the appropriate columns\n",
        "\n",
        "df['is_installed'] = df['is_installed'].map(\n",
        "    clean_is_installed, meta=('is_installed', 'Int64'))\n",
        "df['is_renting'] = df['is_renting'].map(\n",
        "    clean_is_renting_returning, meta=('is_renting', 'Int64'))\n",
        "df['is_returning'] = df['is_returning'].map(\n",
        "    clean_is_renting_returning, meta=('is_returning', 'Int64'))\n",
        "df['num_docks_available'] = df['num_docks_available'].map(\n",
        "    clean_num_docks_available, meta=('num_docks_available', 'Int64'))\n",
        "\n",
        "\n",
        "# Convert 'is_charging_station' to boolean using a custom function\n",
        "\n",
        "\n",
        "\n",
        "df['is_charging_station'] = df['is_charging_station'].map_partitions(\n",
        "    lambda s: s.map(to_bool))\n",
        "\n",
        "# Apply date parsing\n",
        "# df = df.map_partitions(parse_dates)\n",
        "\n",
        "# Convert columns to their appropriate data types\n",
        "df = df.astype({\n",
        "    'station_id': 'Int64',\n",
        "    'num_bikes_available': 'Int64',\n",
        "    'num_bikes_available_types.mechanical': 'Int64',\n",
        "    'num_bikes_available_types.ebike': 'Int64',\n",
        "    'num_docks_available': 'Int64',\n",
        "    'is_installed': 'Int64',\n",
        "    'is_renting': 'Int64',\n",
        "    'is_returning': 'Int64',\n",
        "    'is_charging_station': 'Int64',  # Convert to bool directly\n",
        "    'status': 'object',\n",
        "    'ttl': 'float64'\n",
        "})\n",
        "\n",
        "# Inspect the data before dropping NaN values\n",
        "sample = df.head(10, compute=True)\n",
        "print(\"Sample data before dropping NaNs:\")\n",
        "print(sample)\n",
        "\n",
        "# Check the number of missing values in each column\n",
        "missing_values = df.isna().sum().compute()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Example strategy: Drop rows with NaNs in specific critical columns\n",
        "df = df.dropna(subset=['station_id', 'num_bikes_available', 'is_installed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
